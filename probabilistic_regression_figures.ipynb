{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf08b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "n_samples = int(2e3)\n",
    "x = rng.uniform(low=-3, high=3, size=n_samples)\n",
    "X = x.reshape((n_samples, 1))\n",
    "\n",
    "\n",
    "def true_y_mean(x):\n",
    "    return expit(x) - 0.5 - 0.1 * x\n",
    "\n",
    "\n",
    "def true_y_std(x):\n",
    "    return 0.1 * np.exp(-(x**2) / 0.9)\n",
    "\n",
    "\n",
    "y = rng.normal(loc=true_y_mean(x), scale=true_y_std(x))\n",
    "X_train, X_test, x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, x, y, test_size=0.5, random_state=0\n",
    ")\n",
    "\n",
    "\n",
    "def plot_data_generating_process(\n",
    "    x,\n",
    "    y,\n",
    "    plot_data=True,\n",
    "    max_scatter_points=1_000,\n",
    "    plot_mean=True,\n",
    "    plot_90p_pair=True,\n",
    "    color=\"C0\",\n",
    "    highlight_indices=None,\n",
    "    random_state=0,\n",
    "    ax=None,\n",
    "):\n",
    "    x_grid = np.linspace(x.min(), x.max(), 100)\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(constrained_layout=True)\n",
    "    if plot_data:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        if x.shape[0] > max_scatter_points:\n",
    "            idx = rng.choice(\n",
    "                np.arange(x.shape[0]), size=max_scatter_points, replace=False\n",
    "            )\n",
    "            ax.scatter(x=x[idx], y=y[idx], alpha=0.2, color=\"gray\")\n",
    "        else:\n",
    "            ax.scatter(x=x, y=y, alpha=0.2, color=\"gray\")\n",
    "    \n",
    "    if plot_mean:\n",
    "        ax.plot(x_grid, true_y_mean(x_grid), label=\"$E[Y|X]$\", color=color)\n",
    "    if plot_90p_pair:\n",
    "        ax.plot(\n",
    "            x_grid,\n",
    "            true_y_mean(x_grid) + 1.645 * true_y_std(x_grid),\n",
    "            linestyle=\"--\",\n",
    "            color=color,\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_grid,\n",
    "            true_y_mean(x_grid) - 1.645 * true_y_std(x_grid),\n",
    "            linestyle=\"--\",\n",
    "            label=r\"$Q[Y|X]$\",\n",
    "            color=color,\n",
    "        )\n",
    "        if plot_data and highlight_indices and x.shape[0] <= max_scatter_points:\n",
    "            ax.scatter(\n",
    "                x=x[highlight_indices],\n",
    "                y=y[highlight_indices],\n",
    "                alpha=1,\n",
    "                c=np.arange(len(highlight_indices)),\n",
    "                cmap=\"tab10\",\n",
    "                marker=\"^\",\n",
    "            )\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "plot_data_generating_process(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_train = pd.DataFrame({\"x\": x_train, \"y\": y_train})\n",
    "# df_train.query(\"x > -1.5 & x < -1 & y < 0.1 & y > -0.18\").sort_values(by=\"y\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea69f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_indices = [800, 114, 355, 619, 509, 361]\n",
    "plot_data_generating_process(x_train, y_train, highlight_indices=highlight_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_pinball_loss\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def make_loss_function(loss_name, quantile=0.5, return_label=True):\n",
    "    if loss_name == \"squared_error\":\n",
    "        if return_label:\n",
    "            return mean_squared_error, \"MSE loss\"\n",
    "        else:\n",
    "            return mean_squared_error\n",
    "    elif loss_name == \"quantile\":\n",
    "        if return_label:\n",
    "            return (\n",
    "                partial(mean_pinball_loss, alpha=quantile),\n",
    "                f\"Pinball loss (q={quantile:.2f})\",\n",
    "            )\n",
    "        else:\n",
    "            return partial(mean_pinball_loss, alpha=quantile)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss {loss_name:!r}\")\n",
    "\n",
    "\n",
    "def plot_loss(\n",
    "    loss,\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    highlight_indices=None,\n",
    "    diff_grid_range=None,\n",
    "    quantile=0.6,\n",
    "    data_name=\"train\",\n",
    "    mean_loss=True,\n",
    "    ax=None,\n",
    "):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "    loss_fun, loss_fun_label = make_loss_function(\n",
    "        loss, quantile=quantile, return_label=True\n",
    "    )\n",
    "    if diff_grid_range is None:\n",
    "        # Maximum absolute diff observed for a 0 prediction (e.g. a linear\n",
    "        # model init).\n",
    "        max_abs = np.abs(y_true).max()\n",
    "        diff_grid_range = (-max_abs, max_abs)\n",
    "\n",
    "    if mean_loss:\n",
    "        mean_loss_value = loss_fun(y_true, y_pred)\n",
    "        ax.hlines(\n",
    "            mean_loss_value,\n",
    "            diff_grid_range[0],\n",
    "            diff_grid_range[1],\n",
    "            label=f\"Mean loss value ({data_name}): {mean_loss_value:.3f}\",\n",
    "            linestyle=\"--\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "    n_steps = 100\n",
    "    y_pred_grid = np.linspace(diff_grid_range[0], diff_grid_range[1], n_steps)\n",
    "    ax.plot(\n",
    "        y_pred_grid,\n",
    "        [loss_fun([0], [y_pred_grid_i]) for y_pred_grid_i in y_pred_grid],\n",
    "        color=\"black\",\n",
    "        label=loss_fun_label,\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 5), constrained_layout=True)\n",
    "plot_loss(\"squared_error\", y_train, true_y_mean(x_train), ax=axs[0])\n",
    "plot_loss(\"quantile\", y_train, true_y_mean(x_train), quantile=0.05, ax=axs[2])\n",
    "plot_loss(\"quantile\", y_train, true_y_mean(x_train), quantile=0.95, ax=axs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.linear_model._base import LinearModel\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "def pinball_loss_gradient(X, y, coef, intercept, quantile):\n",
    "    y_pred = X @ coef + intercept\n",
    "    error = y - y_pred\n",
    "    mask = (error >= 0).astype(X.dtype)\n",
    "    weights = -quantile * mask + (1 - quantile) * (1 - mask)\n",
    "    grad_coef = weights @ X / len(y)\n",
    "    grad_intercept = weights.mean()\n",
    "    return grad_coef, grad_intercept\n",
    "\n",
    "\n",
    "class NaiveRegressor(RegressorMixin, LinearModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss=\"squared_error\",\n",
    "        quantile=0.5,\n",
    "        alpha=0,\n",
    "        l1_ratio=0.1,\n",
    "        tol=1e-6,\n",
    "        max_iter=10_000,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.loss = loss\n",
    "        self.quantile = quantile\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        params = np.zeros(X.shape[1] + 1)\n",
    "        n_iter_holder = np.zeros(1, dtype=np.int32)\n",
    "\n",
    "        loss_fun = make_loss_function(\n",
    "            self.loss, quantile=self.quantile, return_label=False\n",
    "        )\n",
    "\n",
    "        def objective(params):\n",
    "            return (\n",
    "                loss_fun(y, X @ params[:-1] + params[-1])\n",
    "                + self.l1_ratio * self.alpha * np.linalg.norm(params[:-1], 1)\n",
    "                + (1 - self.l1_ratio) * self.alpha * np.linalg.norm(params[:-1], 2) ** 2\n",
    "            )\n",
    "\n",
    "        def iter_cb(params):\n",
    "            n_iter_holder[0] += 1\n",
    "            n_iter = n_iter_holder[0]\n",
    "            if self.verbose and n_iter % 10 == 0:\n",
    "                loss = loss_fun(y, X @ params[:-1] + params[-1])\n",
    "                print(f\"{self.loss} at iteration {n_iter}: {loss:.6f}\")\n",
    "            if n_iter_holder[0] >= self.max_iter:\n",
    "                warnings.warn(\n",
    "                    f\"Fail to converge after reaching {self.max_iter} iterations\",\n",
    "                    ConvergenceWarning,\n",
    "                )\n",
    "                raise StopIteration()\n",
    "\n",
    "        result = minimize(objective, params, tol=self.tol, callback=iter_cb)\n",
    "        params = result.x\n",
    "        self.coef_ = params[:-1]\n",
    "        self.intercept_ = params[-1]\n",
    "        self.n_iter_ = n_iter_holder[0]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.coef_ + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54308019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "n_knots = 7\n",
    "shared_params = dict(\n",
    "    tol=1e-4,\n",
    "    max_iter=1000,\n",
    "    alpha=1e-6,\n",
    "    l1_ratio=0.1,\n",
    ")\n",
    "poly_reg_triplet = (\n",
    "    make_pipeline(SplineTransformer(n_knots=n_knots), NaiveRegressor(**shared_params)).fit(\n",
    "        X_train, y_train\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        SplineTransformer(n_knots=n_knots),\n",
    "        NaiveRegressor(loss=\"quantile\", quantile=0.05, **shared_params),\n",
    "    ).fit(X_train, y_train),\n",
    "    make_pipeline(\n",
    "        SplineTransformer(n_knots=n_knots),\n",
    "        NaiveRegressor(loss=\"quantile\", quantile=0.95, **shared_params),\n",
    "    ).fit(X_train, y_train),\n",
    ")\n",
    "tuple(int(getattr(e.steps[-1][1], \"n_iter_\", 1)) for e in poly_reg_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68369573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_triplet(models, x, y, ax=None, color=\"C1\"):\n",
    "    x_grid = np.linspace(x.min(), x.max(), 100)\n",
    "    X_grid = x_grid.reshape((x_grid.shape[0], 1))\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "    ax.plot(x_grid, models[0].predict(X_grid), label=r\"$\\hat{E}[Y|X]$\", color=color)\n",
    "    ax.plot(\n",
    "        x_grid,\n",
    "        models[1].predict(X_grid),\n",
    "        linestyle=\"--\",\n",
    "        color=color,\n",
    "    )\n",
    "    ax.plot(\n",
    "        x_grid,\n",
    "        models[2].predict(X_grid),\n",
    "        linestyle=\"--\",\n",
    "        label=r\"$\\hat{Q}[Y|X]$\",\n",
    "        color=color,\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "plot_data_generating_process(x_train, y_train, ax=ax)\n",
    "plot_model_triplet(poly_reg_triplet, x_train, y_train, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
